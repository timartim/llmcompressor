# Учебный проект, посвященный сжатию текста при помощи авторегрессионной модели. Отчет

## Описание работы 
Данный проект реализует сжатие текста с использованием LSTM модели и адаптивного арифметического кодирования (ААК). 
В папке ./data/ находится текстовый файл enwik5 для сжатия, являющийся первыми 10^5 байтами enwiki-20060303-pages-articles.xml.

Kодировщик использует LSTM/GRU для вычисления вектора вероятностей следующего символа на основе предыдущих. Фактическое значение символа далее кодируется с помощью ААК. Затем веса модели обновляются. Это повторяется для всех символов файла.

Во время декодирования происходит симметричный процесс, декодирование с помощью ААК, предсказание символа при помощи LSTM, обновление модели и т.д.
Декодер работает симметрично, поэтому нет необходимости передавать параметры модели.

В качестве ААК используется реализация из https://github.com/nayuki/Reference-arithmetic-coding 

<table>
  <tr>
    <th>Версия</th>
    <th>Исходный размер, байты</th>
    <th>Размер после сжатия, байты</th>
    <th>Коэффициент сжатия</th>
    <th>Время, с</th>
  </tr>
  <tr>
    <td>Baseline</td>
    <td>100000</td>
    <td>38283</td>
    <td>2.63</td>
    <td>200</td>
  </tr>
  <tr>
    <td>Solution</td>
    <td>100000</td>
    <td>38601</td>
    <td>2.59</td>
    <td>55.64</td>
  </tr>
</table>


## Описание задания к лабораторной работе
Улучшить код так, чтобы он:
- либо **на том же сжатии** показывал **уменьшение времени кодирования и декодирования в 3 раза**; 
- либо обеспечивал **улучшение коэффициента сжатия на 30%** при **тех же временных затратах**. 

Можно улучшать следующие модули:
- Предобработка: замена слова из предварительно созданного словаря уникальным кодом, использование идеи из Byte-Pair Encoding токенизации и т.д.;
- Нейронная сеть: использование другой архитектуры (GRU, Transformer и др.), другой функции активации, изменениями связей между слоями и т.д.;
- Арифметический кодер: можно учесть возможную память источника, использовать другую оценку вероятностей и т.д.

Требования к реализации:
- Результаты должны быть продемонстрированы на enwik5 из папки ./data/;
- Восстановленый после сжатия файл должен полностью совпадать с оригинальным;
- В результатах приложить таблицу выше, обновив значения базового решения для вашего устройства и добавив строчку с улучшенным решением.
- Измерения времени кодирования и декодирования базовой и предложенной версии должны быть выполнены на одном и том же устройстве. 

На почту eabelyaev@itmo.ru прислать отчёт в виде презентации в pdf формате, который включает в себя:
- ФИО студента, номер группы.
- Описание предложенной модификации и результаты.
- Отчёт должен содержать объяснение за счёт чего получилось улучшить базовую архитектуру.
- Ссылку на репозиторий с исходным кодом проекта и инструкцию по запуску.

## Описание ключевых изменений:
1. Замена LSTM на более современный и эффективный GRU, который сопоставим с LSTM по эффективности, но притом требует меньшего числа операций.
Это достигается засчет меньшего числа состояний и ворот. 
2. Уменьшение значения seq_len с 16 до 4, отвечающего за размер контекста, который видит модель. Чем оно больше, тем больше и количество шагов, который должна модель сделать, а следоватекльно медленнее обучение и сжатие данных.
3. Увеличение embedding size с 256 до 1024. Это позволяет накапливать больше информации о каждом символе и о зависимосятх между ними, тем самым увеличивает сложность умножений, но позволяет немного компенсировать значение к/ф сжатия при уменьшение seq_len.
4. Уменьшение rnn_units с 256 до 192. Позволяет снизить количество операций при перемножениях на каждом шаге. 
## Описание инструкции по запуску:
Новое решение находится в файле solution.py. Данные для него находятся в папке data, там же сжатая и декодированная версия файла (enwik5_compressed_optimized.dat, enwik5_decompressed_optimized.dat). 

## Литература
Подробнее про принцип работы можно прочитать в https://bellard.org/nncp/nncp.pdf или https://arxiv.org/pdf/2407.07723 (здесь тот же принцип, но в качестве модели используется LLM и кроме текста сжимают другие типы данных)